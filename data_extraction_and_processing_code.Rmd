---
title: "Post Activity Code Clean Up 11/21"
author: "Marina Chaji"
date: "11/26/2021"
output: html_document
---


# Project setup
Load packages. Install if necessary.

```{r setup, include=TRUE, echo=FALSE, results=FALSE}

PKG <- c("leaflet", "tidyverse", "sf", "ggplot2", "RODM", "dbplyr", "dplyr", "raster","rgdal","readxl")
for (p in PKG) {
  if(!require(p,character.only = TRUE)) {
    install.packages(p)
    require(p,character.only = TRUE)}
}
vintage_string<-Sys.Date()
vintage_string<-gsub("-","_",vintage_string)

```

# Introduction

The main idea of the model is that the fishermen/decision-makers choose from a number of alternatives, where the choice occasion is a fishing trip and selects the one that yields the highest expected utility level on any given choice occasion. By observing and modeling how decision-makers change their preferred site option in response to the changes in the levels of the site attributes, it is possible to determine how decision-makers tradeoff between the different fishing ground characteristics.

# Long Term Objectives
The project objective is to develop a site-choice model primarily, improve, maintain, and disseminate a standardized fisheries dependent data set and analytical summaries that provide a more precise, accurate, comprehensive, and timely evaluation of area-specific socioeconomic impacts associated with ecosystem fishery management initiatives, offshore energy development, and offshore aquaculture development. The site-choice model and underlying data set will help support fishery and ecosystem management decisions to achieve optimum yield in each fishery and the nation’s most significant benefit.


# Purpose

This code extracts and processes data. Our goal is to construct a dataset that can be used to estimate a location choice model at the trip level for the Limited Access Scallop Fishery, using data from 2007-2019 (calendar years).  The main datasource is a frozen DMIS table.

# Dependencies

This code depends on:
1.  Network access to get the APSD_DMIS_2.rda and trip cost data from places on the NEFSC network.
2. An ability to connect to NEFSC oracle databases (VTR and the Live DMIS tables at APSD.t_ssb_trip_current@garfo_nefsc)


# Data Overview

##  Description of the data systems

```{r Data Overview, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
tabl <- "
| Source  | Name           |
|------------|:-----------------------------------------------|
| DMIS_APSD_2   | DMIS is a Northeast Regional Office data record matching system. Primary data sources include Allocation Management System (AMS) Database, Vessel Trip Reports (VTRs), Dealer Reports, Vessel Monitoring System (VMS) Catch Reports, Observer Reports, Vessel Permit Database, and the MQRS database, which tracks limited access fishing eligibilities |
|VTR (Vessel Trip Reports) | A vessel trip report (VTR) must be received by NMFS or postmarked within 15 days after the reporting month’s end.  For vessels that also hold a NE multispecies permit, VTRs must be submitted weekly by Tuesday of the week after the fishing trip ends.  Copies of VTRs must be retained on board the vessel for 1 year after the last entry on the log and otherwise retained for 3 years after the date of the last entry on the log.  If no fishing activity occurred during a reporting period (week or month), then a VTR must be submitted stating that no fishing trips were taken.  |
|Vessel Monitoring System (VMS) | All vessels issued a Federal scallop permit are required to have an active VMS unit and must use their VMS unit to declare all vessel activity, including fishing trips and transiting.|
|Cost data  | Werner et al predict estimate a model of trip costs. Predictions (in and out of sample) are used  |

"
cat(tabl) 
```

##  Description of the DMIS_APSD_2 data.
```{r APSD_DMIS_2 overview, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
tabl <- "
| Column  | Description           |
|------------|:-----------------------------------------------|
|DOCID | VTR DOCUMENT table record identifier; Primary key, internally generated at scanning based on vessel id and date/time sailed. Each DOCID represents one trip; equivalent to TRIPID in VESLOG tables.|
|Dates | VTR land date, AMS Land Date, Dealer Sold Date Trip date is broken down into fields Calendar_Year, Month_of_Year, Week_of_Year, and Day_of_Year|
|DDLAT | Latitude in decimal degrees| 
|DDLON  | Longitude in decimal degrees| 
|PERMIT | Six-digit vessel fishing permit number assigned by the NE Regional Office permit system|
|DOLLAR | This is the value of fish sold.An imputed price is used in cases where the value was not reported.|
|POUNDS | POUNDS is live weight, (in the shell)|
|LANDED |  LANDED can be meat weights or shell weights, but is usually meats|
|TRIP_LENGTH | Trip length is in days; It is calculated from the elapsed time between the date-time sailed and date-time landed. This is a measure of days absent.|
"
cat(tabl) 
```
While not provided in APSD_DMIS_2, we are using the ACTIVITY_CODE from the live DMIS tables. We join using TRIP_ID, DOCID.  See [here](/external_documentation/vms_declaration_code_glossary_may_2018.pdf)


##  Description of the VTR data.
```{r VTR overview, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
tabl <- "
| Column  | Description           |
|------------|:-----------------------------------------------|
|TRIPID|VESLOG Trip record identifier, which is generated internally and used for linking|
|tripcatg | (only commercial categories are selected), recreational and RSA/EFP are not.| 
|operator| Name of the captain|
|opernum| Captains Identification number|
|permit| Six-digit vessel fishing permit number assigned by the NE Regional Office permit system||
|nsubtrip| Number of subtrips (see description of subtrips|
|crew| number of crew, including captain|
"
cat(tabl) 
```

##  Description of the VMS data.
We are currently not using the VMS data directly. 


##  Description of the Cost  data.
```{r Tripcost overview, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
tabl <- "
| Column  | Description           |
|------------|:-----------------------------------------------|
|Place|holder|
|Place|holder|
"
cat(tabl) 
```









# Read in oracle passwords and set network directory
This is a block of code where we set up the oracle passwords and make R aware of folders on the network.

```{r oracle_connections, echo=FALSE, results=FALSE}
source("/net/home4/mchaji/credentials.R")

#Comment one of these out, depending on whether you are running this code on a server or locally (with VPN) 
net<-network_location_desktop
net<-network_location_remote
offshoreWind_directory<-file.path(net,"home5", "dcorvi","OffshoreWind","offshoreWind4","data")

cost_directory<-file.path(net,"work5","socialsci","Trip_Costs","2007-2020")

```


# Load Offshore Wind Tool Data sets 

The frozen DMIS table from the offshoreWind project (APSD_DMIS_2) is the base dataset for the analysis.  The DMIS data are formed by combining many datasets, including VTR and Dealer.  In brief, the APSD_DMIS_2 dataset contains a mix of trip attributes (port, date),  sub-trip attributes (gear, location) , and catch outcomes (species, pounds, landed, dollar).  You can read more about DMIS [here](https://github.com/NEFSC/READ-SSB-Lee-metadata/blob/master/DMIS.md).


```{r Data Set Loading, echo=FALSE, results=FALSE}
load(file.path(offshoreWind_directory, "APSD_DMIS_2.rda"))
#load("~/offshoreWind-master/data-raw/REVENUEFILE.Rdata")
#load("~/offshoreWind-master/data/APSD_DMIS_2.Rdata")
```



# Loading Data fom Oracle 

The APSD_DMIS_2 table must be supplemented with additional data.  This section queries the Oracle databases to extract additional information.

## VTR Data

Some Trip-level data in the VTR schema is needed. See table at the top.  We extract them here. 

```{r VTR_Query, echo=FALSE, results=FALSE}



oracle_server = "sole"
ODBC.CONNECTION <- RODBC::odbcConnect(dsn=oracle_server, uid=oracle_username, pwd=oracle_password, believeNRows=FALSE)
START.YEAR = 2007
END.YEAR = 2019
for(i in START.YEAR:END.YEAR) {
  print(i)
  CURRENT.QUERY = paste("SELECT VTR.veslog",i,"t.TRIPID,tripcatg, operator, opernum, permit, nsubtrip, crew,not_fished  
                FROM VTR.veslog",i,"t", sep="")
  YEAR.RESULT = sqlQuery(ODBC.CONNECTION, CURRENT.QUERY)  
  
  # Now, the loop compiles the results; the first year must be treated slightly differently###
  if (i==START.YEAR) {
    RESULT.COMPILED = YEAR.RESULT
  } else {
    RESULT.COMPILED = rbind(RESULT.COMPILED, YEAR.RESULT) }
}    # End Main Loop


##Subtrip Data
## Note: This data is pulled in order to fill in a large number of blanks in reporting 

  CURRENT.QUERY = paste ("SELECT VTR.veslog",i,"t.TRIPID,tripcatg, operator, opernum, permit, nsubtrip, crew,not_fished  
                FROM VTR.veslog",i,"t", sep="")
  VTR.veslog2019t = sqlQuery(ODBC.CONNECTION, CURRENT.QUERY) 

```



#Loading Data from Oracle
##Scallop LA IFQ Linking variables 
```{r DMIS_Query, echo=FALSE}
 
oracle_server = "sole"

CURRENT.QUERY = paste ("SELECT TRIP_ID, DOCID, ACTIVITY_CODE FROM APSD.t_ssb_trip_current@garfo_nefsc")
Scallop_Linkingorg = sqlQuery(ODBC.CONNECTION, CURRENT.QUERY)

odbcCloseAll()

```

We also extract the activity code from DMIS.  This will describe the type of trip that the vessel has declared into.  The most important types of trips will be Scallop Trips; however, fishing vessels with the proper permits are allowed to retain scallops while declared into other fisheries.  When this happens, the volume of scallops will be much lower.





# Cleaning 
## 1. Filter down to only Scallop Species 
## 2. Seperate Dates & Times and Delete Old Dates Column 
## 3. Delete Columns that are not need 
### NESPP3 & SOURCE Values are all the same so this is deleted 
```{r datacleaning_step1, echo=FALSE}

Scallops <- APSD_DMIS_2 %>% filter (SPPNAME == "SCALLOPS/BUSHEL")

#Separate Dates & Times
Scallops$Date <- as.Date(Scallops$DATE_TRIP)
Scallops$Time <- format(Scallops$DATE_TRIP,"%H:%M:%S")

#Drop columns that are not needed
Scallops$DATE_TRIP<- NULL
Scallops$NESPP3<- NULL
Scallops$SOURCE<- NULL

```






# Merging

1. Merge Scallops & VTR Data Sets (RESULT.COMPILED). We keep all columns from both the APSD_DMIS_2 and RESULT.COMPILED datasets. We also:
     1. Filter out 2020 values 
     1. Delete Extra PERMIT Column because there were a few missing values.
     1. Delete all TRIPCATG that are not 1. This isolates all commercial trips
     1. Drop rows corresponding to a "Not Fished" VTR. 
2. Join the output of (1) with Activity Codes 
3. Verify that we get what we think we should get.

```{r data_merging1, echo=FALSE}

##1. Merge Scallops & VTR Data Sets (RESULT.COMPILED). We keep all columns from both the APSD_DMIS_2 and RESULT.COMPILED datasets. by VTR.TRIPID=APSD_DMIS_2.DOCID

# all.x = TRUE & all.y = FALSE means I am keeping data with no match from DMIS table but dropping data with no match from the Veslog tables

# DOCID is used because of the following found in the data dictionary "VESLOG Trip record identifier, which is generated internally; Primary key for VESLOGyyyyT; Foreign key to VESLOGyyS, VESLOGyyG. Equivalent to DOCID in VTR DOCUMENT table"
VTR_DMIS_merge <- merge(RESULT.COMPILED,Scallops, by.x = "TRIPID", by.y = "DOCID", all.x = FALSE, all.y = TRUE)

## Filter out 2020 values 
VTR_DMIS_merge <- VTR_DMIS_merge %>% filter(YEAR != 2020)

# Delete Extra PERMIT Column
## Note: X was deleted because PERMIT.y had zero NAs and PERMIT.x had 25 
VTR_DMIS_merge$PERMIT.x <- NULL

# Delete all TRIPCATG that are not 1. This isolates all commercial trips
## Type of trip: 1=Commercial; 2=Party; 3=Charter; 4=RSA/EFP. Note: RSA/EFP landings represent a small amount of all commercial landings; landings vary by gear type and species.

VTR_DMIS_merge <- VTR_DMIS_merge %>% filter(TRIPCATG == "1")
VTR_DMIS_merge$TRIPCATG <- NULL

# Delete all NOT_FISHED that are not 0. This indicates whether the 'Did not fish' box was checked on the Vessel Trip Report. 0=Fishing activity; 1=No fishing activity/Negative report.
VTR_DMIS_merge <- VTR_DMIS_merge %>% filter(NOT_FISHED == "0")
VTR_DMIS_merge$NOT_FISHED <- NULL


## 2. 
###Join VTR & DMIS Data with Activity Codes 

# Delete duplicate rows; These are rows that share the same TRIPID, DOLLAR,LANDED, & TRIP_LENGTH 
## Note: VTRs are self-reported and there is a potential for records to be submitted to regional office multiple times; on rare occasions this can result in duplicate records being logged.
VTR_DMIS_AC <- merge(VTR_DMIS_merge,Scallop_Linkingorg, by.x = "TRIPID", by.y = "DOCID", all.x = TRUE, all.y = FALSE)
VTR_DMIS_AC <- VTR_DMIS_AC %>% distinct(TRIPID,DOLLAR,TRIP_LENGTH,LANDED, .keep_all = TRUE)  

## 3. 
### Testing Reported NAs in new data set (that they are relatively even across all years)
#### Note: The variable used in this command can be substituted for whatever needs to be tested. In this case I am testing OPERNUM, because that will be used to determine decisions in the model 

testing <- VTR_DMIS_AC %>%
group_by("YEAR") %>% filter(is.na(OPERNUM))


```





# Data Aggregating Trip Revenues & Delete duplicate TRIPIDs
Subtrips are generated when a vessel switches gear or areas. Subtrips have identical TRIPID/DOCID.  A trip may have many (8+) subtrips, but most have 1-2.

```{r count_subtrips}
table(VTR_DMIS_AC$NSUBTRIP)
```

Since our goal is to estimate a choice model at the trip level, we need to construct trip level variables.  
 We retained the subtrip attributes  (GEARCODE, DDLAT, DDLON) corresponding to the subtrip with the highest DOLLAR.  We constructed trip-level values for revenue, pounds, and landed (DOLLAR, POUNDS, LANDED).  The trip level variables are prefixed with "Agg_". 

###  1. Aggregate DOLLAR, POUNDS, LANDED
###  2. Add back into orginial data set 
###  3. Check / Test Maximum DOLLAR values by grouping by TRIPID
###  4. Drop duplicate TRIPIDs by keeping maximum DOLLAR values 



# Trips reported on land will be dropped from observations 

```{r desktop_spatial}

# Load libraries
PKG <- c("sp", "rgdal", "raster", "sf", "dplyr", "tidyr", "stringr", "data.table")
for (p in PKG) {
  if(!require(p,character.only = TRUE)) {
    install.packages(p)
    require(p,character.only = TRUE)}
}


#################################################################################################
# change these variables to read in the veslogDMISmerge and what the network path to the shared drive is on your laptop
coordinate_table_input <-VTR_DMIS_AC
lat_column = "DDLAT"
lon_column = "DDLON"
shapefile_path = "~/East_Cst_crop_2020_extended"
#################################################################################################
shapefile_path_to_spatialpolygons <- function(shapefile_path,
                                              projection = CRS("+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0")) {

  # shapefile_path = "C:/Users/dennis.corvi/Documents/R/Projects/OffshoreWindDev/offshoreWind/areas_minus_SF"
  # projection = CRS("+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0")
  layer_name = unique(gsub(pattern="(.+)(.shp$)","\\1", ignore.case = TRUE , list.files(path=shapefile_path, pattern = "(.+)(.shp$)", ignore.case =TRUE, recursive=F, full.names=F)))
  if (length(layer_name)==0) {
    stop("Shapefile path does not contain a shapefile")
  }
  if (length(layer_name) > 1) {
    file_list <- list.files(shapefile_path, pattern = "*shp$", full.names = TRUE)
    shapefile_list <- lapply(file_list, sf::read_sf)
    all_shapes <- sf::st_as_sf(data.table::rbindlist(shapefile_list))
    all_shapes <- all_shapes[,(names(all_shapes) %in% c("Name"))]
    all_shapes <- sf::as_Spatial(all_shapes, cast = TRUE, IDs = paste0("ID", seq_along(from)))
    all_shapes@data$NAME <- all_shapes@data$Name
    all_shapes@data$Name <- NULL
  } else { # if only one shape
    all_shapes <- rgdal::readOGR(dsn=shapefile_path, layer=layer_name, verbose=F)
  }
  all_shapes <- spTransform(all_shapes, CRS=projection)
  return(all_shapes)
}
#################################################################################################

crs = CRS("+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0")
shapefile_area <- SpatialPolygonsDataFrame(aggregate(shapefile_path_to_spatialpolygons(shapefile_path, projection = crs)), data = data.frame("NAME" = "Land"))
coordinate_table <- as_tibble(coordinate_table_input %>%
                                rename("LAT" = .data[[lat_column]], "LON" = .data[[lon_column]]) %>%
                                drop_na(LON, LAT) %>%
                                mutate(LON = if_else(LON>1, LON*-1, LON )) %>%
                                relocate(LON, LAT)) # drop LAT LON NAs, correct LON, change column order - check if any longitudes are positive and switch to negative

xy <- coordinate_table[,c(1,2)]
coordinate_table <- SpatialPointsDataFrame(coords = xy, data = coordinate_table, proj4string = crs)
coordinate_table <- spTransform(coordinate_table, CRSobj = crs)

vtridx <- over(coordinate_table, shapefile_area)

colnames(vtridx)[1] <- "NAME"

coordinate_table$Area <- vtridx$NAME
coordinate_table <- coordinate_table@data

VTR_DMIS_AC <- coordinate_table %>%
  mutate_if(is.factor, as.character) %>%
  mutate(Area = if_else(is.na(Area), "Non-land", Area)) %>% # change NAs to read "Non-land"
  rename("{lat_column}" := LAT, "{lon_column}" := LON) %>%  # change lat lon columns back to original names
  filter(Area == "Non-land")

# finished table is coordinate_table

write.csv(VTR_DMIS_AC, file="~/December 2021/VTR_DMIS_AC_postwater_1217.csv")

```

```{r construct_trip_aggregates}
### 1. Aggregate DOLLAR, POUNDS, LANDED
Agg_DOL_POUN_LAND <- VTR_DMIS_AC %>%
  group_by(TRIPID) %>%
 summarise(Agg_DOLLAR = sum(DOLLAR), Agg_POUNDS = sum(POUNDS), Agg_LANDED = sum(LANDED))

#### Testing to make sure there are no duplicates in TRIPID groups; this should equal 0
sum(duplicated(Agg_DOL_POUN_LAND$TRIPID))
stopifnot(sum(duplicated(Agg_DOL_POUN_LAND$TRIPID))==0)

###  2. Add back into original data set 
#### all = FALSE is used to keep only rows that match from the data frames
VTR_DMIS_AC_Agg <- merge(VTR_DMIS_AC,Agg_DOL_POUN_LAND, by.x = "TRIPID", by.y = "TRIPID", all.x = TRUE, all.y = FALSE)




### 3.Parse out Maximum Dollar amounts in order to drop lesser subtrips
VTR_DMIS_AC_Agg <- VTR_DMIS_AC_Agg %>% group_by(TRIPID) %>% filter(DOLLAR == max(DOLLAR))
### Another way to check this is by running the following code: VTR_DMIS_AC_Agg %>% group_by(TRIPID) %>% arrange(desc(DOLLAR)) %>% slice(1)

## Test out 
sum(duplicated(VTR_DMIS_AC_Agg$TRIPID))

stopifnot(sum(duplicated(VTR_DMIS_AC_Agg$TRIPID))==0)


```






#Import data set only including water observations
## 1. Data is imported from RStudio on Desktop
## 2. Data is imported from ArcGISPro
### A spatial join is done with Water data, Ten Minute Squares, & Lease Areas shape file. Points are assigned to Ten Minute Squares and Lease areas on a one to one joint point basis for observations within a square. This can be adjusted later by adding buffers.  
```{r reading_spatial_join}

## Delete unnecessary columns 
water_ac$Area <- NULL

library(readr)
X11_29_21_Spatial_Join <- read_csv("11_29_21_Spatial_Join.csv")
View(X11_29_21_Spatial_Join)

##Check that observations between water points and ArcGIS are the same

```




# Estimated Limited Access (LA) Fleet Filter
We considered filtering out the LADAS scallop fleet by using landings greater than or equal to 850 pounds and Crew less than or equal to 8. These are based on crew limits. In summary:

FY2007-2014: No limit on crew (except for 7 in DMV starting in FY2014)
FY2015-2019: 8

> Initially, vessels had the same crew limits in access areas as they did on DAS.  However, Framework 18(fishing year 2006) eliminated the seven-person crew limit (five-person limit for small dredge category vessels) for scallop access area trips. The purpose of this was to eliminate inefficiencies caused by the crew limit for fishing activity that is limited by a possession limit. The crew limit was established to control vessels’ shucking capacity when fishing under DAS. 

> Eight years later, Framework 25 (fishing year 2014) imposed a crew limit of seven individuals (the same as DAS) per limited access vessel (five-person limit for small dredge category vessels) in DMV.  The purpose of this was to protect small scallops and discourage vessels from highgrading.

>Framework 26 (fishing year 2015) implemented crew limits for all access areas. In an effort to protect small scallops and discourage vessels from high-grading.  Framework 26 imposed a crew limit of eight individuals (one extra from DAS) per limited access vessel, including the captain, when fishing in any scallop access area. If a vessel is participating in the small dredge program, it may not have more than six people (one extra from DAS) on board, including the captain, on an access area trip. 

>Finally, because the scallops in the NLS–S–D were expected to have lower yield than similar sized scallops in other areas, Framework 32 (fishing year 2020) allowed two additional crew members aboard both limited access full-time (10 in total) and limited access full-time small dredge vessels (8 in total). This allowed vessels to add additional crew members to increase the shucking capacity of the vessel and reach the possession limit in a time more consistent with other access areas. (Travis Ford @ GARFO - Nov 17,2021)


FY2007-2014: No limit (except for 7 in DMV starting in FY2014)
FY2015-2019: 8



## This might be temporary; still looking into different integration methods with activity codes
```{r filter_LA1}
LA_Estimate <- X11_29_21_Spatial_Join %>% filter(Agg_LANDED >= 850 & CREW <= 8)

```

#Add in cost data 

These data should reference the  "Estimation of Commercial Fishing Trip Costs Using Sea Sampling Data" paper by Samantha Werner & Geret DePiper.  We will likely use the Winsorized trip cost estimates.
```{r merge_cost_data}
#Import Data
X2007_2012 <- read_excel(file.path(cost_directory,"2007_2012.xlsx"))
X2013_2020 <- read_excel(file.path(cost_directory,"2013_2020.xlsx"))

#Merge 2007-2012 costs with 2013-2020 costs
all_yrs_costs <- merge(X2007_2012,X2013_2020, all = TRUE)
## Created two sets of cost joins.
### 1. Before LA Estimation
### 2. After LA Estimation
cost_join <- merge(X11_29_21_Spatial_Join,all_yrs_costs, by.x = "TRIPID", by.y = "VTR_TRIPID", all.x = TRUE,all.y =FALSE)
cost_join_LA <-merge(LA_Estimate,all_yrs_costs, by.x = "TRIPID", by.y = "VTR_TRIPID", all.x = TRUE,all.y =FALSE)  

```

```{r summary_statistics}
# Here is a placeholder where we will make a few summary statistics tables.  Nothing too fancy. This may be sufficient.
# This has not been tested. Yet.

summary(cost_join)

table(cost_join$YEAR)

table(cost_join$GEARCODE)

table(cost_join$STATE)


```






